{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e1b9536",
   "metadata": {},
   "source": [
    "<h1 style=\"font-family: Helvetica; font-size: 29px\"> Notebook: Preprocessing Arabic Music Data for Variational Auto Encoder Generation Model</h1>\n",
    "<p style=\"font-size: 16px; font-family: Times New Roman;\">This Notebook is based on the preprocessing done by Valerio Velardo for VAE based model. We edited some parameters to fitin with our data. \n",
    "In this notebook, data is preprocced through piplining process, started by segmenting audio files each <b>5.94 seconds</b> , then padding them if necessary , then extracting Log specttrograms to use in model training , then applying min_max normlizer to use it in post processing , and finally we call all of that to save them in the mentioned paths, as an extra step we extract the log spectrograms Images to observe the music trends given frequency and time.\n",
    "The data being preprocessed is <b>75<b> Wav files , segmented into <b>8756<b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c00333",
   "metadata": {},
   "source": [
    "<h1 style=\"font-family: Helvetica; font-size: 28px\"> Loading Necessary Libraries</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d038ce29",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 16px; font-family: Times New Roman;\">\n",
    "This cell of code imports the necessary libraries and modules needed for audio processing\n",
    "os is used for file system operations. pickle is used for serializing and de-serializing Python object structures. librosa is a Python package for music and audio analysis. pydub is a high-level audio library that makes it easy to work with audio files. soundfile is a Python library for reading and writing audio files. io provides Python's core input/output support.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0559a1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import librosa\n",
    "from pydub import AudioSegment\n",
    "import soundfile as sf\n",
    "from matplotlib import pyplot as plt\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import io\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59d662e",
   "metadata": {},
   "source": [
    "<h1 style=\"font_family:Helvetica; font-size:28px\"> Segment Wav files</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e741b5a",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 16px; font-family: Times New Roman;\">\n",
    "The code in the cell below defines a function named 'Segment' that segments audio files into smaller segments of a specified length using a sliding window approach. The input to the function is a folder containing audio files, and the output is a folder where the segmented audio files will be saved.\n",
    "Overall, this code is useful for preprocessing audio files for tasks such as speech recognition, music genre classification, or any other audio-based machine learning tasks that require the audio files to be segmented or as we used it in preprocessing for generation model.</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f2b165",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Segment(input_folder, output_folder):\n",
    "    segment_length = 2.97\n",
    "    hop_length = 2\n",
    "    \n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\".wav\"):\n",
    "            ## Set input and output file paths\n",
    "            input_path = os.path.join(input_folder, filename)\n",
    "            output_path = os.path.join(output_folder, filename)\n",
    "\n",
    "            # Load audio file using librosa\n",
    "            y, sr = librosa.load(input_path, sr=None)\n",
    "\n",
    "            # Calculate segment frame and sample lengths\n",
    "            segment_frames = int(segment_length * sr)\n",
    "            hop_frames = int(hop_length * sr)\n",
    "            total_frames = len(y)\n",
    "            total_segments = int((total_frames - segment_frames) / hop_frames) + 1\n",
    "\n",
    "            # Segment audio using a sliding window\n",
    "            for i in range(total_segments):\n",
    "                # Calculate start and end frame indices for current segment\n",
    "                start_frame = i * hop_frames\n",
    "                end_frame = start_frame + segment_frames\n",
    "\n",
    "                # Extract audio segment\n",
    "                y_segment = y[start_frame:end_frame]\n",
    "\n",
    "                # Set output file path for current segment\n",
    "                output_segment_path = output_path.replace(\".wav\", f\"_segment{i}.wav\")\n",
    "\n",
    "                # Save audio segment to file\n",
    "                #librosa.output.write_wav(output_segment_path, y_segment, sr)\n",
    "                sf.write(output_segment_path, y_segment, sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991c100d",
   "metadata": {},
   "source": [
    "<h1 style=\"font-family: Helvetica; font-size: 28px\"> Load the files</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0a71a5",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 16px; font-family: Times New Roman;\">\n",
    "The Loader class is used to load audio files with specific parameters. It takes in three arguments: sample_rate, duration, and mono. sample_rate.This class is useful when working with large audio datasets and allows for easy and customizable loading of audio files. </p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645898c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loader:\n",
    "\n",
    "    def __init__(self, sample_rate, duration, mono):\n",
    "        self.sample_rate = sample_rate\n",
    "        self.duration = duration\n",
    "        self.mono = mono\n",
    "\n",
    "    def load(self, file_path):\n",
    "        signal = librosa.load(file_path,\n",
    "                              sr=self.sample_rate,\n",
    "                              duration=self.duration,\n",
    "                              mono=self.mono)[0]\n",
    "        return signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03275bd5",
   "metadata": {},
   "source": [
    "<h1 style=\"font-family: Helvetica; font-size: 28px\"> Padding if necessary </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4677504",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16xp : font_family :Times New Romans; \">In the cell below, The Padder class is designed to add padding to an array using '0' to make it a certain size. The class has two methods, left_pad and right_pad, which take an array and the number of missing items as inputs. The mode parameter sets the type of padding to be used, which defaults to \"constant\". The left_pad method adds padding to the left side of the array, while the right_pad method adds padding to the right side of the array. Both methods return the padded array.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f915753",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Padder:\n",
    "\n",
    "    def __init__(self, mode=\"constant\"):\n",
    "        self.mode = mode\n",
    "\n",
    "    def left_pad(self, array, num_missing_items):\n",
    "        padded_array = np.pad(array,\n",
    "                              (num_missing_items, 0),\n",
    "                              mode=self.mode)\n",
    "        return padded_array\n",
    "\n",
    "    def right_pad(self, array, num_missing_items):\n",
    "        padded_array = np.pad(array,\n",
    "                              (0, num_missing_items),\n",
    "                              mode=self.mode)\n",
    "        return padded_array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a866a96f",
   "metadata": {},
   "source": [
    "<h1 style=\"font-family: Helvetica; font-size: 28px\">Extracting log_spectrogram</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3418db44",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16xp : font_family :Times New Romans; \">In the cell below ,The LogSpectrogramExtractor class is responsible for extracting a log-scaled spectrogram from an audio signal. It takes in two parameters during initialization, frame_size and hop_length, which determine the size of the short-time Fourier transform (STFT) window and the number of samples to advance the window respectively. In the extract method, the signal is first transformed using STFT, and the magnitude of the complex-valued STFT is computed. The magnitude spectrogram is then converted to decibel scale using librosa.amplitude_to_db, which applies a logarithmic compression to the spectrogram. The resulting log-spectrogram is returned by the method. We usend log_seoctrogram in previous classification task and here we are using it in  generation model.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aefb0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogSpectrogramExtractor:\n",
    "\n",
    "    def __init__(self, frame_size, hop_length):\n",
    "        self.frame_size = frame_size\n",
    "        self.hop_length = hop_length\n",
    "\n",
    "    def extract(self, signal):\n",
    "        stft = librosa.stft(signal,\n",
    "                            n_fft=self.frame_size,\n",
    "                            hop_length=self.hop_length)[:-1]\n",
    "        spectrogram = np.abs(stft)\n",
    "        log_spectrogram = librosa.amplitude_to_db(spectrogram)\n",
    "        return log_spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b15865",
   "metadata": {},
   "source": [
    "<h1 style=\"font-family: Helvetica; font-size: 28px\">Min_Max Normaliser</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2646a17b",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16xp : font_family :Times New Romans; \">The MinMaxNormaliser class applies min-max normalization to an input array. It is used to scale an array of values to a specified range, defined by min_val and max_val. The class contains two main methods: normalise and denormalise. The normalise method takes an input array, calculates its minimum and maximum values, and scales the array to the range specified by min_val and max_val. The resulting normalized array is returned. The denormalise method takes a normalized array, the original minimum and maximum values of the input array, and scales the normalized array back to the original range. This is useful for our  task as we normalize the arrays for generation then, denormalise for postprocessing to return to original value.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb906b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinMaxNormaliser:\n",
    "    \"\"\"MinMaxNormaliser applies min max normalisation to an array.\"\"\"\n",
    "\n",
    "    def __init__(self, min_val, max_val):\n",
    "        self.min = min_val\n",
    "        self.max = max_val\n",
    "\n",
    "    def normalise(self, array):\n",
    "        norm_array = (array - array.min()) / (array.max() - array.min())\n",
    "        norm_array = norm_array * (self.max - self.min) + self.min\n",
    "        return norm_array\n",
    "\n",
    "    def denormalise(self, norm_array, original_min, original_max):\n",
    "        array = (norm_array - self.min) / (self.max - self.min)\n",
    "        array = array * (original_max - original_min) + original_min\n",
    "        return array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c170da",
   "metadata": {},
   "source": [
    "<h1 style=\"font-family: Helvetica; font-size: 28px\">Saver</h1>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efc4cb6",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16xp : font_family :Times New Romans; \"> The cell below is responsible to save features and min_max values.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700294df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Saver:\n",
    "\n",
    "    def __init__(self, feature_save_dir, min_max_values_save_dir):\n",
    "        self.feature_save_dir = feature_save_dir\n",
    "        self.min_max_values_save_dir = min_max_values_save_dir\n",
    "\n",
    "    def save_feature(self, feature, file_path):\n",
    "        save_path = self._generate_save_path(file_path)\n",
    "        np.save(save_path, feature)\n",
    "\n",
    "    def save_min_max_values(self, min_max_values):\n",
    "        save_path = os.path.join(self.min_max_values_save_dir,\n",
    "                                 \"min_max_values.pkl\")\n",
    "        self._save(min_max_values, save_path)\n",
    "\n",
    "    @staticmethod\n",
    "    def _save(data, save_path):\n",
    "        with open(save_path, \"wb\") as f:\n",
    "            pickle.dump(data, f)\n",
    "\n",
    "    def _generate_save_path(self, file_path):\n",
    "        file_name = os.path.split(file_path)[1]\n",
    "        save_path = os.path.join(self.feature_save_dir, file_name + \".npy\")\n",
    "        return save_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0552de",
   "metadata": {},
   "source": [
    "<h1 style=\"font-family: Helvetica; font-size: 28px\">Extracting log_spectrogram</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ce66ce",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16xp : font_family :Times New Romans; \"> The cell below expalins Preprocessing Pipeline processes audio files in a directory, applying\n",
    "    the following steps to each file: <ol>\n",
    "  <li>Load a file</li>\n",
    "  <li>Pad the signal (if necessary)</li>\n",
    "  <li>Extract log spectrogram from signal</li>\n",
    "  <li>Normalise spectrogram</li>\n",
    "  <li>Save the normalised spectrogram</li>\n",
    "   </ol></p>\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679924d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessingPipeline:\n",
    "    \n",
    "    def __init__(self):\n",
    "        #self.padder = None\n",
    "        self.extractor = None\n",
    "        self.normaliser = None\n",
    "        self.saver = None\n",
    "        self.min_max_values = {}\n",
    "        self._loader = None\n",
    "        self._num_expected_samples = None\n",
    "\n",
    "    @property\n",
    "    def loader(self):\n",
    "        return self._loader\n",
    "\n",
    "    @loader.setter\n",
    "    def loader(self, loader):\n",
    "        self._loader = loader\n",
    "        self._num_expected_samples = int(loader.sample_rate * loader.duration)\n",
    "\n",
    "    def process(self, audio_files_dir):\n",
    "        for root, _, files in os.walk(audio_files_dir):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                self._process_file(file_path)\n",
    "                print(f\"Processed file {file_path}\")\n",
    "        self.saver.save_min_max_values(self.min_max_values)\n",
    "\n",
    "    def _process_file(self, file_path):\n",
    "        signal = self.loader.load(file_path)\n",
    "        #if self._is_padding_necessary(signal):\n",
    "            #signal = self._apply_padding(signal)\n",
    "        feature = self.extractor.extract(signal)\n",
    "        norm_feature = self.normaliser.normalise(feature)\n",
    "        save_path = self.saver.save_feature(norm_feature, file_path)\n",
    "        self._store_min_max_value(save_path, feature.min(), feature.max())\n",
    "\n",
    "    #def _is_padding_necessary(self, signal):\n",
    "        #if len(signal) < self._num_expected_samples:\n",
    "            #return True\n",
    "        #return False\n",
    "\n",
    "    #def _apply_padding(self, signal):\n",
    "        #num_missing_samples = self._num_expected_samples - len(signal)\n",
    "        #padded_signal = self.padder.right_pad(signal, num_missing_samples)\n",
    "        #return padded_signal\n",
    "\n",
    "    def _store_min_max_value(self, save_path, min_val, max_val):\n",
    "        self.min_max_values[save_path] = {\n",
    "            \"min\": min_val,\n",
    "            \"max\": max_val\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a9a5ac",
   "metadata": {},
   "source": [
    "<h1 style=\"font-family: Helvetica; font-size: 28px\">Call Segement Function</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b119d1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = r\"E:\\E just\\Spring 3rd Year\\PBL\\generation\\Generation by one genre\\class wav\"\n",
    "seg_out = r\"E:\\E just\\Spring 3rd Year\\PBL\\generation\\Generation by one genre\\wav new shape\"\n",
    "Segment(input_folder, seg_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c657a6",
   "metadata": {},
   "source": [
    "<h1 style=\"font-family: Helvetica; font-size: 28px\"> Instantiate all objects</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1e0c73",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16xp : font_family :Times New Romans; \">The code in the cell below instantiates several objects and sets up a preprocessing pipeline for audio files.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25d9500",
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAME_SIZE = 512\n",
    "HOP_LENGTH = 256\n",
    "DURATION = 2.97 # in seconds\n",
    "SAMPLE_RATE = 22050\n",
    "MONO = True\n",
    "\n",
    "SPECTROGRAMS_SAVE_DIR = r\"path link\"\n",
    "MIN_MAX_VALUES_SAVE_DIR = r\"E:\\E just\\Spring 3rd Year\\PBL\\generation\\Generation by one genre\\min_max\"\n",
    "FILES_DIR = seg_out\n",
    "\n",
    "# instantiate all objects\n",
    "loader = Loader(SAMPLE_RATE, DURATION, MONO)\n",
    "#padder = Padder()\n",
    "log_spectrogram_extractor = LogSpectrogramExtractor(FRAME_SIZE, HOP_LENGTH)\n",
    "min_max_normaliser = MinMaxNormaliser(0, 1)\n",
    "saver = Saver(SPECTROGRAMS_SAVE_DIR, MIN_MAX_VALUES_SAVE_DIR)\n",
    "\n",
    "preprocessing_pipeline = PreprocessingPipeline()\n",
    "preprocessing_pipeline.loader = loader\n",
    "#preprocessing_pipeline.padder = padder\n",
    "preprocessing_pipeline.extractor = log_spectrogram_extractor\n",
    "preprocessing_pipeline.normaliser = min_max_normaliser\n",
    "preprocessing_pipeline.saver = saver\n",
    "\n",
    "preprocessing_pipeline.process(FILES_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b180512",
   "metadata": {},
   "source": [
    "<h1 style=\"font-family: Helvetica; font-size: 28px\"> Extract Log-Spectrograms images</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2c61d2",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16xp : font_family :Times New Romans; \"> In the cell below, the code is extracting the log spectrograms images from the log spectrogram numpy arrays using matplot.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3762b9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "spectrogram_path = r\"E:\\E just\\Spring 3rd Year\\PBL\\generation\\test generation trial3\\log_numpy\"\n",
    "images_path = r\"E:\\E just\\Spring 3rd Year\\PBL\\generation\\test generation trial3\\log_images\"\n",
    "\n",
    "for file_name in os.listdir(spectrogram_path):\n",
    "    file_path = os.path.join(spectrogram_path, file_name)\n",
    "    img_path = os.path.join(images_path, file_name.replace('.npy', '_mel_spec.png'))\n",
    "    spectrogram = np.load(file_path)\n",
    "    \n",
    "    # Plot the spectrogram as an image\n",
    "    plt.imshow(spectrogram, origin='lower', aspect='auto')\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Mel bins')\n",
    "    plt.title('Log Mel Spectrogram')\n",
    "    plt.savefig(img_path)\n",
    "    plt.clf()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
