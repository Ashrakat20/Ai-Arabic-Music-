{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19c00333",
   "metadata": {},
   "source": [
    "<h1 style=\"font-family: Helvetica; font-size: 28px\"> Loading Necessary Libraries</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ee51d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import librosa\n",
    "from pydub import AudioSegment\n",
    "import soundfile as sf\n",
    "from matplotlib import pyplot as plt\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import io\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9eee65ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization, \\\n",
    "    Flatten, Dense, Reshape, Conv2DTranspose, Activation, Lambda\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "\n",
    "# Remove the following line\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# Code continues...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59d662e",
   "metadata": {},
   "source": [
    "<h1 style=\"font_family:Helvetica; font-size:28px\"> Segment Wav files</h1> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34f2b165",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Segment(input_folder, output_folder):\n",
    "    segment_length = 2.97\n",
    "    hop_length = 2\n",
    "    \n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\".wav\"):\n",
    "            ## Set input and output file paths\n",
    "            input_path = os.path.join(input_folder, filename)\n",
    "            output_path = os.path.join(output_folder, filename)\n",
    "\n",
    "            # Load audio file using librosa\n",
    "            y, sr = librosa.load(input_path, sr=None)\n",
    "\n",
    "            # Calculate segment frame and sample lengths\n",
    "            segment_frames = int(segment_length * sr)\n",
    "            hop_frames = int(hop_length * sr)\n",
    "            total_frames = len(y)\n",
    "            total_segments = int((total_frames - segment_frames) / hop_frames) + 1\n",
    "\n",
    "            # Segment audio using a sliding window\n",
    "            for i in range(total_segments):\n",
    "                # Calculate start and end frame indices for current segment\n",
    "                start_frame = i * hop_frames\n",
    "                end_frame = start_frame + segment_frames\n",
    "\n",
    "                # Extract audio segment\n",
    "                y_segment = y[start_frame:end_frame]\n",
    "\n",
    "                # Set output file path for current segment\n",
    "                output_segment_path = output_path.replace(\".wav\", f\"_segment{i}.wav\")\n",
    "\n",
    "                # Save audio segment to file\n",
    "                #librosa.output.write_wav(output_segment_path, y_segment, sr)\n",
    "                sf.write(output_segment_path, y_segment, sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991c100d",
   "metadata": {},
   "source": [
    "<h1 style=\"font-family: Helvetica; font-size: 28px\"> Load the files</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "645898c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loader:\n",
    "\n",
    "    def __init__(self, sample_rate, duration, mono):\n",
    "        self.sample_rate = sample_rate\n",
    "        self.duration = duration\n",
    "        self.mono = mono\n",
    "\n",
    "    def load(self, file_path):\n",
    "        signal = librosa.load(file_path,\n",
    "                              sr=self.sample_rate,\n",
    "                              duration=self.duration,\n",
    "                              mono=self.mono)[0]\n",
    "        return signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03275bd5",
   "metadata": {},
   "source": [
    "<h1 style=\"font-family: Helvetica; font-size: 28px\"> Padding if necessary </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f915753",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Padder:\n",
    "\n",
    "    def __init__(self, mode=\"constant\"):\n",
    "        self.mode = mode\n",
    "\n",
    "    def left_pad(self, array, num_missing_items):\n",
    "        padded_array = np.pad(array,\n",
    "                              (num_missing_items, 0),\n",
    "                              mode=self.mode)\n",
    "        return padded_array\n",
    "\n",
    "    def right_pad(self, array, num_missing_items):\n",
    "        padded_array = np.pad(array,\n",
    "                              (0, num_missing_items),\n",
    "                              mode=self.mode)\n",
    "        return padded_array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a866a96f",
   "metadata": {},
   "source": [
    "<h1 style=\"font-family: Helvetica; font-size: 28px\">Extracting log_spectrogram</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7aefb0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogSpectrogramExtractor:\n",
    "\n",
    "    def __init__(self, frame_size, hop_length):\n",
    "        self.frame_size = frame_size\n",
    "        self.hop_length = hop_length\n",
    "\n",
    "    def extract(self, signal):\n",
    "        stft = librosa.stft(signal,\n",
    "                            n_fft=self.frame_size,\n",
    "                            hop_length=self.hop_length)[:-1]\n",
    "        spectrogram = np.abs(stft)\n",
    "        log_spectrogram = librosa.amplitude_to_db(spectrogram)\n",
    "        return log_spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b15865",
   "metadata": {},
   "source": [
    "<h1 style=\"font-family: Helvetica; font-size: 28px\">Min_Max Normaliser</h1> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aeb906b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinMaxNormaliser:\n",
    "    \"\"\"MinMaxNormaliser applies min max normalisation to an array.\"\"\"\n",
    "\n",
    "    def __init__(self, min_val, max_val):\n",
    "        self.min = min_val\n",
    "        self.max = max_val\n",
    "\n",
    "    def normalise(self, array):\n",
    "        norm_array = (array - array.min()) / (array.max() - array.min())\n",
    "        norm_array = norm_array * (self.max - self.min) + self.min\n",
    "        return norm_array\n",
    "\n",
    "    def denormalise(self, norm_array, original_min, original_max):\n",
    "        array = (norm_array - self.min) / (self.max - self.min)\n",
    "        array = array * (original_max - original_min) + original_min\n",
    "        return array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c170da",
   "metadata": {},
   "source": [
    "<h1 style=\"font-family: Helvetica; font-size: 28px\">Saver</h1>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "700294df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Saver:\n",
    "\n",
    "    def __init__(self, feature_save_dir, min_max_values_save_dir):\n",
    "        self.feature_save_dir = feature_save_dir\n",
    "        self.min_max_values_save_dir = min_max_values_save_dir\n",
    "\n",
    "    def save_feature(self, feature, file_path):\n",
    "        save_path = self._generate_save_path(file_path)\n",
    "        np.save(save_path, feature)\n",
    "        return file_path\n",
    "    def save_min_max_values(self, min_max_values):\n",
    "        save_path = os.path.join(self.min_max_values_save_dir,\n",
    "                                 \"min_max_values.pkl\")\n",
    "        self._save(min_max_values, save_path)\n",
    "\n",
    "    @staticmethod\n",
    "    def _save(data, save_path):\n",
    "        with open(save_path, \"wb\") as f:\n",
    "            pickle.dump(data, f)\n",
    "\n",
    "    def _generate_save_path(self, file_path):\n",
    "        file_name = os.path.split(file_path)[1]\n",
    "        save_path = os.path.join(self.feature_save_dir, file_name + \".npy\")\n",
    "        return save_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0552de",
   "metadata": {},
   "source": [
    "<h1 style=\"font-family: Helvetica; font-size: 28px\">Extracting log_spectrogram</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "679924d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessingPipeline:\n",
    "    \n",
    "    def __init__(self):\n",
    "        #self.padder = None\n",
    "        self.extractor = None\n",
    "        self.normaliser = None\n",
    "        self.saver = None\n",
    "        self.min_max_values = {}\n",
    "        self._loader = None\n",
    "        self._num_expected_samples = None\n",
    "\n",
    "    @property\n",
    "    def loader(self):\n",
    "        return self._loader\n",
    "\n",
    "    @loader.setter\n",
    "    def loader(self, loader):\n",
    "        self._loader = loader\n",
    "        self._num_expected_samples = int(loader.sample_rate * loader.duration)\n",
    "\n",
    "    def process(self, audio_files_dir):\n",
    "        for root, _, files in os.walk(audio_files_dir):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                self._process_file(file_path)\n",
    "                print(f\"Processed file {file_path}\")\n",
    "        self.saver.save_min_max_values(self.min_max_values)\n",
    "\n",
    "    def _process_file(self, file_path):\n",
    "        signal = self.loader.load(file_path)\n",
    "        if self._is_padding_necessary(signal):\n",
    "            signal = self._apply_padding(signal)\n",
    "        feature = self.extractor.extract(signal)\n",
    "        norm_feature = self.normaliser.normalise(feature)\n",
    "        save_path = self.saver.save_feature(norm_feature, file_path)\n",
    "        self._store_min_max_value(save_path, feature.min(), feature.max())\n",
    "\n",
    "    def _is_padding_necessary(self, signal):\n",
    "        if len(signal) < self._num_expected_samples:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def _apply_padding(self, signal):\n",
    "        num_missing_samples = self._num_expected_samples - len(signal)\n",
    "        padded_signal = self.padder.right_pad(signal, num_missing_samples)\n",
    "        return padded_signal\n",
    "\n",
    "    def _store_min_max_value(self, save_path, min_val, max_val):\n",
    "        self.min_max_values[save_path] = {\n",
    "            \"min\": min_val,\n",
    "            \"max\": max_val\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a9a5ac",
   "metadata": {},
   "source": [
    "<h1 style=\"font-family: Helvetica; font-size: 28px\">Call Segement Function</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b119d1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = r\"E:\\E just\\Spring 3rd Year\\PBL\\generation\\Generation by one genre\\class wav\"\n",
    "seg_out = r\"E:\\E just\\Spring 3rd Year\\PBL\\generation\\Generation by one genre\\wav new shape\"\n",
    "#Segment(input_folder, seg_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c657a6",
   "metadata": {},
   "source": [
    "<h1 style=\"font-family: Helvetica; font-size: 28px\"> Instantiate all objects</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d25d9500",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SPECTROGRAMS_SAVE_DIR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m log_spectrogram_extractor \u001b[38;5;241m=\u001b[39m LogSpectrogramExtractor(FRAME_SIZE, HOP_LENGTH)\n\u001b[0;32m     15\u001b[0m min_max_normaliser \u001b[38;5;241m=\u001b[39m MinMaxNormaliser(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m saver \u001b[38;5;241m=\u001b[39m Saver(\u001b[43mSPECTROGRAMS_SAVE_DIR\u001b[49m, MIN_MAX_VALUES_SAVE_DIR)\n\u001b[0;32m     18\u001b[0m preprocessing_pipeline \u001b[38;5;241m=\u001b[39m PreprocessingPipeline()\n\u001b[0;32m     19\u001b[0m preprocessing_pipeline\u001b[38;5;241m.\u001b[39mloader \u001b[38;5;241m=\u001b[39m loader\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SPECTROGRAMS_SAVE_DIR' is not defined"
     ]
    }
   ],
   "source": [
    "FRAME_SIZE = 512\n",
    "HOP_LENGTH = 256\n",
    "DURATION = 2.97 # in seconds\n",
    "SAMPLE_RATE = 22050\n",
    "MONO = True\n",
    "\n",
    "SPECTROGRAMS_SAVE_DIR = r\"E:\\E just\\Spring 3rd Year\\PBL\\generation\\Generation by one genre\\n\"\n",
    "MIN_MAX_VALUES_SAVE_DIR = r\"E:\\E just\\Spring 3rd Year\\PBL\\generation\\Generation by one genre\\min_max_values\"\n",
    "FILES_DIR =r\"E:\\E just\\Spring 3rd Year\\PBL\\generation\\Generation by one genre\\wav_segments\"\n",
    "\n",
    "# instantiate all objects\n",
    "loader = Loader(SAMPLE_RATE, DURATION, MONO)\n",
    "padder = Padder()\n",
    "log_spectrogram_extractor = LogSpectrogramExtractor(FRAME_SIZE, HOP_LENGTH)\n",
    "min_max_normaliser = MinMaxNormaliser(0, 1)\n",
    "saver = Saver(SPECTROGRAMS_SAVE_DIR, MIN_MAX_VALUES_SAVE_DIR)\n",
    "\n",
    "preprocessing_pipeline = PreprocessingPipeline()\n",
    "preprocessing_pipeline.loader = loader\n",
    "preprocessing_pipeline.padder = padder\n",
    "preprocessing_pipeline.extractor = log_spectrogram_extractor\n",
    "preprocessing_pipeline.normaliser = min_max_normaliser\n",
    "preprocessing_pipeline.saver = saver\n",
    "\n",
    "preprocessing_pipeline.process(FILES_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1765c69",
   "metadata": {},
   "source": [
    "# VAE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c046e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e90939a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calculate_reconstruction_loss(y_target, y_predicted):\n",
    "    error = y_target - y_predicted\n",
    "    reconstruction_loss = K.mean(K.square(error), axis=[1, 2, 3])\n",
    "    return reconstruction_loss\n",
    "\n",
    "\n",
    "def calculate_kl_loss(model):\n",
    "    # wrap `_calculate_kl_loss` such that it takes the model as an argument,\n",
    "    # returns a function which can take arbitrary number of arguments\n",
    "    # (for compatibility with `metrics` and utility in the loss function)\n",
    "    # and returns the kl loss\n",
    "    def _calculate_kl_loss(*args):\n",
    "        kl_loss = -0.5 * K.sum(1 + model.log_variance - K.square(model.mu) -\n",
    "                               K.exp(model.log_variance), axis=1)\n",
    "        return kl_loss\n",
    "    return _calculate_kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0f94f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE:\n",
    "    \"\"\"\n",
    "    VAE represents a Deep Convolutional variational autoencoder architecture\n",
    "    with mirrored encoder and decoder components.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_shape,\n",
    "                 conv_filters,\n",
    "                 conv_kernels,\n",
    "                 conv_strides,\n",
    "                 latent_space_dim):\n",
    "        self.input_shape = input_shape\n",
    "        self.conv_filters = conv_filters \n",
    "        self.conv_kernels = conv_kernels \n",
    "        self.conv_strides = conv_strides \n",
    "        self.latent_space_dim = latent_space_dim \n",
    "        self.reconstruction_loss_weight = 1000000\n",
    "\n",
    "        self.encoder = None\n",
    "        self.decoder = None\n",
    "        self.model = None\n",
    "\n",
    "        self._num_conv_layers = len(conv_filters)\n",
    "        self._shape_before_bottleneck = None\n",
    "        self._model_input = None\n",
    "\n",
    "        self._build()\n",
    "\n",
    "    def summary(self):\n",
    "        self.encoder.summary()\n",
    "        self.decoder.summary()\n",
    "        self.model.summary()\n",
    "\n",
    "        \n",
    "  \n",
    "\n",
    "    def compile(self, learning_rate=0.0001):\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "        self.model.compile(optimizer=optimizer,\n",
    "                           loss=self._calculate_combined_loss,\n",
    "                           metrics=[_calculate_reconstruction_loss,\n",
    "                                    calculate_kl_loss(self)])\n",
    "\n",
    "    def train(self, x_train, batch_size, num_epochs, callbacks=None):\n",
    "        self.model.fit(x_train,\n",
    "                       x_train,\n",
    "                       batch_size=batch_size,\n",
    "                       epochs=num_epochs,\n",
    "                       shuffle=True, callbacks=[checkpoint_callback] + callbacks)\n",
    "\n",
    "    def save(self, save_folder=\".\"):\n",
    "        self._create_folder_if_it_doesnt_exist(save_folder)\n",
    "        self._save_parameters(save_folder)\n",
    "        self._save_weights(save_folder)\n",
    "\n",
    "    def load_weights(self, weights_path):\n",
    "        self.model.load_weights(weights_path)\n",
    "\n",
    "    def reconstruct(self, images):\n",
    "        latent_representations = self.encoder.predict(images)\n",
    "        reconstructed_images = self.decoder.predict(latent_representations)\n",
    "        return reconstructed_images, latent_representations\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, save_folder=\".\"):\n",
    "        parameters_path = os.path.join(save_folder, \"parameters.pkl\")\n",
    "        with open(parameters_path, \"rb\") as f:\n",
    "            parameters = pickle.load(f)\n",
    "        autoencoder = VAE(*parameters)\n",
    "        weights_path = os.path.join(save_folder, \"weights.h5\")\n",
    "        autoencoder.load_weights(weights_path)\n",
    "        return autoencoder\n",
    "\n",
    "    def _calculate_combined_loss(self, y_target, y_predicted):\n",
    "        reconstruction_loss = self._calculate_reconstruction_loss(y_target, y_predicted)\n",
    "        kl_loss = self._calculate_kl_loss(y_target, y_predicted)\n",
    "        combined_loss = self.reconstruction_loss_weight * reconstruction_loss\\\n",
    "        + kl_loss\n",
    "        combined_loss=reconstruction_loss\n",
    "        return combined_loss\n",
    "\n",
    "    def _calculate_reconstruction_loss(self, y_target, y_predicted):\n",
    "        error = y_target - y_predicted\n",
    "        reconstruction_loss = K.mean(K.square(error), axis=[1, 2, 3])\n",
    "        return reconstruction_loss\n",
    "\n",
    "    def _calculate_kl_loss(self, y_target, y_predicted):\n",
    "        kl_loss = -0.5 * K.sum(1 + self.log_variance - K.square(self.mu) -\n",
    "                               K.exp(self.log_variance), axis=1)\n",
    "        return kl_loss\n",
    "\n",
    "    def _create_folder_if_it_doesnt_exist(self, folder):\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "\n",
    "    def _save_parameters(self, save_folder):\n",
    "        parameters = [\n",
    "            self.input_shape,\n",
    "            self.conv_filters,\n",
    "            self.conv_kernels,\n",
    "            self.conv_strides,\n",
    "            self.latent_space_dim\n",
    "        ]\n",
    "        save_path = os.path.join(save_folder, \"parameters.pkl\")\n",
    "        with open(save_path, \"wb\") as f:\n",
    "            pickle.dump(parameters, f)\n",
    "\n",
    "    def _save_weights(self, save_folder):\n",
    "        save_path = os.path.join(save_folder, \"weights.h5\")\n",
    "        self.model.save_weights(save_path)\n",
    "\n",
    "    def _build(self):\n",
    "        self._build_encoder()\n",
    "        self._build_decoder()\n",
    "        self._build_autoencoder()\n",
    "\n",
    "    def _build_autoencoder(self):\n",
    "        model_input = self._model_input\n",
    "        model_output = self.decoder(self.encoder(model_input))\n",
    "        self.model = Model(model_input, model_output, name=\"autoencoder\")\n",
    "\n",
    "    def _build_decoder(self):\n",
    "        decoder_input = self._add_decoder_input()\n",
    "        dense_layer = self._add_dense_layer(decoder_input)\n",
    "        reshape_layer = self._add_reshape_layer(dense_layer)\n",
    "        conv_transpose_layers = self._add_conv_transpose_layers(reshape_layer)\n",
    "        decoder_output = self._add_decoder_output(conv_transpose_layers)\n",
    "        self.decoder = Model(decoder_input, decoder_output, name=\"decoder\")\n",
    "\n",
    "    def _add_decoder_input(self):\n",
    "        return Input(shape=self.latent_space_dim, name=\"decoder_input\")\n",
    "\n",
    "    def _add_dense_layer(self, decoder_input):\n",
    "        num_neurons = np.prod(self._shape_before_bottleneck) # [1, 2, 4] -> 8\n",
    "        dense_layer = Dense(num_neurons, name=\"decoder_dense\")(decoder_input)\n",
    "        return dense_layer\n",
    "\n",
    "    def _add_reshape_layer(self, dense_layer):\n",
    "        return Reshape(self._shape_before_bottleneck)(dense_layer)\n",
    "\n",
    "    def _add_conv_transpose_layers(self, x):\n",
    "        \"\"\"Add conv transpose blocks.\"\"\"\n",
    "        # loop through all the conv layers in reverse order and stop at the\n",
    "        # first layer\n",
    "        for layer_index in reversed(range(1, self._num_conv_layers)):\n",
    "            x = self._add_conv_transpose_layer(layer_index, x)\n",
    "        return x\n",
    "\n",
    "    def _add_conv_transpose_layer(self, layer_index, x):\n",
    "        layer_num = self._num_conv_layers - layer_index\n",
    "        conv_transpose_layer = Conv2DTranspose(\n",
    "            filters=self.conv_filters[layer_index],\n",
    "            kernel_size=self.conv_kernels[layer_index],\n",
    "            strides=self.conv_strides[layer_index],\n",
    "            padding=\"same\",\n",
    "            name=f\"decoder_conv_transpose_layer_{layer_num}\"\n",
    "        )\n",
    "        x = conv_transpose_layer(x)\n",
    "        x = ReLU(name=f\"decoder_relu_{layer_num}\")(x)\n",
    "        x = BatchNormalization(name=f\"decoder_bn_{layer_num}\")(x)\n",
    "        return x\n",
    "\n",
    "    def _add_decoder_output(self, x):\n",
    "        conv_transpose_layer = Conv2DTranspose(\n",
    "            filters=1,\n",
    "            kernel_size=self.conv_kernels[0],\n",
    "            strides=self.conv_strides[0],\n",
    "            padding=\"same\",\n",
    "            name=f\"decoder_conv_transpose_layer_{self._num_conv_layers}\"\n",
    "        )\n",
    "        x = conv_transpose_layer(x)\n",
    "        output_layer = Activation(\"sigmoid\", name=\"sigmoid_layer\")(x)\n",
    "        return output_layer\n",
    "\n",
    "    def _build_encoder(self):\n",
    "        encoder_input = self._add_encoder_input()\n",
    "        conv_layers = self._add_conv_layers(encoder_input)\n",
    "        bottleneck = self._add_bottleneck(conv_layers)\n",
    "        self._model_input = encoder_input\n",
    "        self.encoder = Model(encoder_input, bottleneck, name=\"encoder\")\n",
    "\n",
    "    def _add_encoder_input(self):\n",
    "        return Input(shape=self.input_shape, name=\"encoder_input\")\n",
    "\n",
    "    def _add_conv_layers(self, encoder_input):\n",
    "        \"\"\"Create all convolutional blocks in encoder.\"\"\"\n",
    "        x = encoder_input\n",
    "        for layer_index in range(self._num_conv_layers):\n",
    "            x = self._add_conv_layer(layer_index, x)\n",
    "        return x\n",
    "\n",
    "    def _add_conv_layer(self, layer_index, x):\n",
    "        \"\"\"Add a convolutional block to a graph of layers, consisting of\n",
    "        conv 2d + ReLU + batch normalization.\n",
    "        \"\"\"\n",
    "        layer_number = layer_index + 1\n",
    "        conv_layer = Conv2D(\n",
    "            filters=self.conv_filters[layer_index],\n",
    "            kernel_size=self.conv_kernels[layer_index],\n",
    "            strides=self.conv_strides[layer_index],\n",
    "            padding=\"same\",\n",
    "            name=f\"encoder_conv_layer_{layer_number}\"\n",
    "        )\n",
    "        x = conv_layer(x)\n",
    "        x = ReLU(name=f\"encoder_relu_{layer_number}\")(x)\n",
    "        x = BatchNormalization(name=f\"encoder_bn_{layer_number}\")(x)\n",
    "        return x\n",
    "\n",
    "    def _add_bottleneck(self, x):\n",
    "        \"\"\"Flatten data and add bottleneck with Guassian sampling (Dense\n",
    "        layer).\n",
    "        \"\"\"\n",
    "        self._shape_before_bottleneck = K.int_shape(x)[1:]\n",
    "        x = Flatten()(x)\n",
    "        self.mu = Dense(self.latent_space_dim, name=\"mu\")(x)\n",
    "        self.log_variance = Dense(self.latent_space_dim,\n",
    "                                  name=\"log_variance\")(x)\n",
    "\n",
    "        def sample_point_from_normal_distribution(args):\n",
    "            mu, log_variance = args\n",
    "            epsilon = K.random_normal(shape=K.shape(self.mu), mean=0.,\n",
    "                                      stddev=1.)\n",
    "            sampled_point = mu + K.exp(log_variance / 2) * epsilon\n",
    "            return sampled_point\n",
    "\n",
    "        x = Lambda(sample_point_from_normal_distribution,\n",
    "                   name=\"encoder_output\")([self.mu, self.log_variance])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c348741",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# create a ModelCheckpoint callback to save the best model\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='E:/E just/Spring 3rd Year/PBL/generation/test generation trial3/epochone/model_weights_best.h5',\n",
    "    save_weights_only=True,\n",
    "    monitor='loss',  # monitor validation loss to determine the best model\n",
    "    save_best_only=True,  # save only the best model\n",
    "    save_freq='epoch'  # save after each epoch\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ee5a946",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.00005\n",
    "BATCH_SIZE = 1\n",
    "EPOCHS = 6\n",
    "SPECTROGRAMS_PATH = r\"E:\\E just\\Spring 3rd Year\\PBL\\generation\\spoken digits\\100_sample_npy\"\n",
    "\n",
    "\n",
    "def load_fsdd(spectrograms_path):\n",
    "    x_train = []\n",
    "    for root, _, file_names in os.walk(spectrograms_path):\n",
    "        for file_name in file_names:\n",
    "            file_path = os.path.join(root, file_name)\n",
    "            spectrogram = np.load(file_path)\n",
    "            if np.count_nonzero(np.isnan(spectrogram)):\n",
    "                print(f\"Avoided\")\n",
    "                continue\n",
    "            x_train.append(spectrogram)\n",
    "    x_train = np.array(x_train)\n",
    "    x_train = x_train[..., np.newaxis] # -> (3500, 256,512 , 1)\n",
    "    return x_train\n",
    "\n",
    "def train(x_train, learning_rate, batch_size, epochs, callbacks=None):\n",
    "    autoencoder = VAE(\n",
    "        input_shape=(256, 64, 1),\n",
    "        conv_filters=(512, 256, 128, 64, 32),\n",
    "        conv_kernels=(3, 3, 3, 3, 3),\n",
    "        conv_strides=(1, 2, 2, 2, 1),\n",
    "        latent_space_dim = 128\n",
    "    )\n",
    "    autoencoder.summary()\n",
    "    autoencoder.compile(learning_rate)\n",
    "    autoencoder.load_weights(r'D:\\Education\\Semester 6\\CSE 321 Project Based Learning on CSE\\Generation one genre\\Epoch one\\model_weights_best.h5')\n",
    "    autoencoder.train(x_train, batch_size, epochs, callbacks=[])\n",
    "    return autoencoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc1d9761",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = r\"D:\\Education\\Semester 6\\CSE 321 Project Based Learning on CSE\\Generation one genre\\x_train.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a235cc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if __name__ == \"__main__\":\n",
    "    #x_train = load_fsdd(SPECTROGRAMS_PATH)\n",
    "    #x_train = np.load(path)\n",
    "    #autoencoder = train(x_train, LEARNING_RATE, BATCH_SIZE, EPOCHS,callbacks=[])\n",
    "    #autoencoder.save(r\"D:\\Education\\Semester 6\\CSE 321 Project Based Learning on CSE\\Generation one genre\\Epoch one)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4358cdb",
   "metadata": {},
   "source": [
    "# Post-processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "30d0889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import soundfile as sf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "be0a14f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoundGenerator:\n",
    "    \"\"\"SoundGenerator is responsible for generating audios from\n",
    "    spectrograms.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vae, hop_length):\n",
    "        self.vae = vae\n",
    "        self.hop_length = hop_length\n",
    "        self._min_max_normaliser = MinMaxNormaliser(0, 1)\n",
    "\n",
    "    def generate(self, spectrograms, min_max_values):\n",
    "        generated_spectrograms, latent_representations = \\\n",
    "            self.vae.reconstruct(spectrograms)\n",
    "        signals = self.convert_spectrograms_to_audio(generated_spectrograms, min_max_values)\n",
    "        return signals, latent_representations\n",
    "\n",
    "    def convert_spectrograms_to_audio(self, spectrograms, min_max_values):\n",
    "        signals = []\n",
    "        for spectrogram, min_max_value in zip(spectrograms, min_max_values):\n",
    "            # reshape the log spectrogram\n",
    "            log_spectrogram = spectrogram[:, :, 0]\n",
    "            # apply denormalisation\n",
    "            denorm_log_spec = self._min_max_normaliser.denormalise(\n",
    "                log_spectrogram, min_max_value[\"min\"], min_max_value[\"max\"])\n",
    "            # log spectrogram -> spectrogram\n",
    "            spec = librosa.db_to_amplitude(denorm_log_spec)\n",
    "            # apply Griffin-Lim\n",
    "            signal = librosa.istft(spec, hop_length=self.hop_length)\n",
    "            # append signal to \"signals\"\n",
    "            signals.append(signal)\n",
    "        return signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e40bc925",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOP_LENGTH = 256\n",
    "SAVE_DIR_ORIGINAL =r\"E:\\E just\\Spring 3rd Year\\PBL\\generation\\Generation by one genre\\original\"\n",
    "SAVE_DIR_GENERATED = r\"E:\\E just\\Spring 3rd Year\\PBL\\generation\\Generation by one genre\\generated\"\n",
    "MIN_MAX_VALUES_PATH = \"E:\\E just\\Spring 3rd Year\\PBL\\generation\\Generation by one genre\\min_max_values\\min_max_values.pkl\"\n",
    "SPECTROGRAMS_PATH =r\"E:\\E just\\Spring 3rd Year\\PBL\\generation\\Generation by one genre\\n\"\n",
    "\n",
    "def load_fsdd(spectrograms_path):\n",
    "    x_train = []\n",
    "    file_paths = []\n",
    "    for root, _, file_names in os.walk(spectrograms_path):\n",
    "        for file_name in file_names:\n",
    "            file_path = os.path.join(root, file_name)\n",
    "            spectrogram = np.load(file_path) # (n_bins, n_frames, 1)\n",
    "            x_train.append(spectrogram)\n",
    "            file_paths.append(os.path.basename(file_path))  # Use only the file name\n",
    "    x_train = np.array(x_train)\n",
    "    x_train = x_train[..., np.newaxis] # -> (3000, 256, 64, 1)\n",
    "    return x_train, file_paths\n",
    "\n",
    "\n",
    "def select_spectrograms(spectrograms, file_paths, min_max_values, num_spectrograms=2):\n",
    "    sampled_specs = []\n",
    "    sampled_min_max_values = []\n",
    "    \n",
    "    sampled_indexes = np.random.choice(range(len(spectrograms)), num_spectrograms)\n",
    "    \n",
    "    for index in sampled_indexes:\n",
    "        file_path = file_paths[index]\n",
    "        file_path = \"E:\\\\E just\\\\Spring 3rd Year\\\\PBL\\\\generation\\\\Generation by one genre\\\\n\\\\\"  + file_path\n",
    "        if file_path in min_max_values:\n",
    "            sampled_specs.append(spectrograms[index])\n",
    "            sampled_min_max_values.append(min_max_values[file_path])\n",
    "    \n",
    "    #print(file_paths)\n",
    "    #print(sampled_min_max_values)\n",
    "    \n",
    "    return np.array(sampled_specs), sampled_min_max_values\n",
    "\n",
    "\n",
    "\n",
    "def save_signals(signals, save_dir, sample_rate=22050):\n",
    "    for i, signal in enumerate(signals):\n",
    "        save_path = os.path.join(save_dir, str(i) + \".wav\")\n",
    "        sf.write(save_path, signal, sample_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a5b29a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MBR\\anaconda3\\lib\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # initialise sound generator\n",
    "    vae = VAE.load(r\"E:\\E just\\Spring 3rd Year\\PBL\\generation\\Generation by one genre\\model\")\n",
    "    sound_generator = SoundGenerator(vae, HOP_LENGTH)\n",
    "\n",
    "    # load spectrograms + min max values\n",
    "    with open(MIN_MAX_VALUES_PATH, \"rb\") as f:\n",
    "        min_max_values = pickle.load(f)\n",
    "    #print(min_max_values)\n",
    "    specs, file_paths = load_fsdd(SPECTROGRAMS_PATH)\n",
    "\n",
    "    # sample spectrograms + min max values\n",
    "    sampled_specs, sampled_min_max_values = select_spectrograms(specs,\n",
    "                                                                file_paths,\n",
    "                                                                min_max_values,\n",
    "                                                                5)\n",
    "    \n",
    "    #print(sampled_specs)\n",
    "    #print(sampled_min_max_values)\n",
    "    # generate audio for sampled spectrograms\n",
    "    signals, _ = sound_generator.generate(sampled_specs,\n",
    "                                          sampled_min_max_values)\n",
    "\n",
    "    # convert spectrogram samples to audio\n",
    "    original_signals = sound_generator.convert_spectrograms_to_audio(\n",
    "        sampled_specs, sampled_min_max_values)\n",
    "\n",
    "    # save audio signals\n",
    "    save_signals(signals, SAVE_DIR_GENERATED)\n",
    "    save_signals(original_signals, SAVE_DIR_ORIGINAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179cb9da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924e6a81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
