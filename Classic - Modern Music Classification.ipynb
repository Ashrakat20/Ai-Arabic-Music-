{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pydub import AudioSegment\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from matplotlib import pyplot as plt\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import io\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Swp_y3lKq0GU"
   },
   "source": [
    "# **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "on_WQ1KTng6r"
   },
   "source": [
    "**Convert MP3 to WAV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Ebw9s7UcKHY"
   },
   "outputs": [],
   "source": [
    "mp3_folder = \"/content/drive/MyDrive/Classification_Classic-Modern/Modern/mohamed rahem composer\"\n",
    "wav_folder = \"/content/drive/MyDrive/Classification_Classic-Modern/Modern/Modern_WAV\"\n",
    "\n",
    "# Loop over all files in the input folder\n",
    "for filename in os.listdir(mp3_folder):\n",
    "    if filename.endswith(\".mp3\"):\n",
    "        # Set input and output file paths\n",
    "        mp3_path = os.path.join(mp3_folder, filename)\n",
    "        wav_path = os.path.join(wav_folder, os.path.splitext(filename)[0] + \".wav\")\n",
    "\n",
    "        # Load MP3 file using pydub\n",
    "        audio = AudioSegment.from_mp3(mp3_path)\n",
    "\n",
    "        # Export audio in WAV format\n",
    "        audio.export(wav_path, format=\"wav\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2BIwV_sCnncS"
   },
   "source": [
    "**Normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8kFkn2OLXHCi"
   },
   "outputs": [],
   "source": [
    "input_folder = \"/content/drive/MyDrive/Classification_Classic-Modern/Modern/Modern_WAV\"\n",
    "output_folder = \"/content/drive/MyDrive/Classification_Classic-Modern/Modern/Normalized\"\n",
    "\n",
    "# Loop over all files in the input folder\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        # Set input and output file paths\n",
    "        input_path = os.path.join(input_folder, filename)\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "\n",
    "        # Load audio file using librosa\n",
    "        y, sr = librosa.load(input_path, sr=None)\n",
    "\n",
    "        # Normalize audio using peak amplitude normalization\n",
    "        y_normalized = librosa.util.normalize(y)\n",
    "\n",
    "        # Save normalized audio to file\n",
    "        #librosa.output.write_wav(output_path, y_normalized, sr)\n",
    "        sf.write(output_path, y_normalized, sr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y2fIdf-woO9c"
   },
   "source": [
    "**Onset Segmentation for Classical Dataset of length 5 seconds**\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EmLvKDlCoUZ_"
   },
   "outputs": [],
   "source": [
    "input_folder = \"/content/drive/MyDrive/Classification_Classic-Modern/Classic/Normalized\"\n",
    "output_folder = \"/content/drive/MyDrive/Classification_Classic-Modern/Classic/Segmented\"\n",
    "\n",
    "# Set segment length and hop length in seconds\n",
    "segment_length = 5\n",
    "hop_length = 2\n",
    "\n",
    "# Loop over all files in the input folder\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        # Set input and output file paths\n",
    "        input_path = os.path.join(input_folder, filename)\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "\n",
    "        # Load audio file using librosa\n",
    "        y, sr = librosa.load(input_path, sr=None)\n",
    "\n",
    "        # Calculate segment frame and sample lengths\n",
    "        segment_frames = int(segment_length * sr)\n",
    "        hop_frames = int(hop_length * sr)\n",
    "        total_frames = len(y)\n",
    "        total_segments = int((total_frames - segment_frames) / hop_frames) + 1\n",
    "\n",
    "        # Segment audio using a sliding window\n",
    "        for i in range(total_segments):\n",
    "            # Calculate start and end frame indices for current segment\n",
    "            start_frame = i * hop_frames\n",
    "            end_frame = start_frame + segment_frames\n",
    "\n",
    "            # Extract audio segment\n",
    "            y_segment = y[start_frame:end_frame]\n",
    "\n",
    "            # Set output file path for current segment\n",
    "            output_segment_path = output_path.replace(\".wav\", f\"_segment{i}.wav\")\n",
    "\n",
    "            # Save audio segment to file\n",
    "            #librosa.output.write_wav(output_segment_path, y_segment, sr)\n",
    "            sf.write(output_segment_path, y_segment, sr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JiiLE2ZOqfRw"
   },
   "source": [
    "**Onset Segmentation for Modern Dataset of length 5 seconds**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wP1dD_u_rc6c"
   },
   "outputs": [],
   "source": [
    "input_folder = \"/content/drive/MyDrive/Classification_Classic-Modern/Modern/Normalized\"\n",
    "output_folder = \"/content/drive/MyDrive/Classification_Classic-Modern/Modern/Segmented\"\n",
    "\n",
    "# Set segment length and hop length in seconds\n",
    "segment_length = 5\n",
    "hop_length = 2\n",
    "\n",
    "# Loop over all files in the input folder\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        # Set input and output file paths\n",
    "        input_path = os.path.join(input_folder, filename)\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "\n",
    "        # Load audio file using librosa\n",
    "        y, sr = librosa.load(input_path, sr=None)\n",
    "\n",
    "        # Calculate segment frame and sample lengths\n",
    "        segment_frames = int(segment_length * sr)\n",
    "        hop_frames = int(hop_length * sr)\n",
    "        total_frames = len(y)\n",
    "        total_segments = int((total_frames - segment_frames) / hop_frames) + 1\n",
    "\n",
    "        # Segment audio using a sliding window\n",
    "        for i in range(total_segments):\n",
    "            # Calculate start and end frame indices for current segment\n",
    "            start_frame = i * hop_frames\n",
    "            end_frame = start_frame + segment_frames\n",
    "\n",
    "            # Extract audio segment\n",
    "            y_segment = y[start_frame:end_frame]\n",
    "\n",
    "            # Set output file path for current segment\n",
    "            output_segment_path = output_path.replace(\".wav\", f\"_segment{i}.wav\")\n",
    "\n",
    "            # Save audio segment to file\n",
    "            #librosa.output.write_wav(output_segment_path, y_segment, sr)\n",
    "            sf.write(output_segment_path, y_segment, sr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5-RTtEqKdphU"
   },
   "source": [
    "# **Extracting Mel-Spectrogram for Classic Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F5lE6vzbdv24"
   },
   "outputs": [],
   "source": [
    "# Set up parameters for Mel spectrogram\n",
    "n_fft = 2048\n",
    "hop_length = 512\n",
    "n_mels = 128\n",
    "\n",
    "# Set up folder paths\n",
    "input_folder = \"D:\\Education\\Semester 6\\CSE 321 Project Based Learning on CSE\\Classification_Classic-Modern\\Classic\\Segmented\"\n",
    "output_folder = \"D:\\Education\\Semester 6\\CSE 321 Project Based Learning on CSE\\Classification_Classic-Modern\\Classic\\Mel-Spectrogram\"\n",
    "\n",
    "# Loop over files in input folder\n",
    "for file_name in os.listdir(input_folder):\n",
    "    # Check if file is a WAV file\n",
    "    if not file_name.endswith('.wav'):\n",
    "        continue\n",
    "\n",
    "    # Load audio file using librosa\n",
    "    file_path = os.path.join(input_folder, file_name)\n",
    "    y, sr = librosa.load(file_path)\n",
    "    \n",
    "    # Extracting Mel Spectrogram\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y, sr=sr, n_fft=2048, hop_length=512, n_mels=10)\n",
    "    \n",
    "    # Converting to db\n",
    "    log_mel_spectrogram = librosa.power_to_db(mel_spectrogram)\n",
    "\n",
    "    output_path = os.path.join(output_folder, file_name.replace('.wav', '_mel_spec.png'))\n",
    "    \n",
    "    # Extracting PNG\n",
    "    plt.figure(figsize=(25, 10))\n",
    "    librosa.display.specshow(log_mel_spectrogram, \n",
    "                             x_axis=\"time\",\n",
    "                             y_axis=\"mel\", \n",
    "                             sr=sr)\n",
    "    plt.colorbar(format=\"%+2.f\")\n",
    "    plt.savefig(output_path)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Extracting Mel-Spectrogram for Modern Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up parameters for Mel spectrogram\n",
    "n_fft = 2048\n",
    "hop_length = 512\n",
    "n_mels = 128\n",
    "\n",
    "# Set up folder paths\n",
    "input_folder = \"D:\\Education\\Semester 6\\CSE 321 Project Based Learning on CSE\\Classification_Classic-Modern\\Modern\\Segmented\"\n",
    "output_folder = \"D:\\Education\\Semester 6\\CSE 321 Project Based Learning on CSE\\Classification_Classic-Modern\\Modern\\Mel-spectrogram\"\n",
    "counter = 1\n",
    "# Loop over files in input folder\n",
    "for file_name in os.listdir(input_folder):\n",
    "    # Check if file is a WAV file\n",
    "    print(counter)\n",
    "    counter += 1\n",
    "    if not file_name.endswith('.wav'):\n",
    "        continue\n",
    "\n",
    "    # Load audio file using librosa\n",
    "    file_path = os.path.join(input_folder, file_name)\n",
    "    y, sr = librosa.load(file_path)\n",
    "    \n",
    "    # Extracting Mel Spectrogram\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y, sr=sr, n_fft=2048, hop_length=512, n_mels=10)\n",
    "    \n",
    "    # Converting to db\n",
    "    log_mel_spectrogram = librosa.power_to_db(mel_spectrogram)\n",
    "\n",
    "    output_path = os.path.join(output_folder, file_name.replace('.wav', '_mel_spec.png'))\n",
    "    \n",
    "    # Extracting PNG\n",
    "    plt.figure(figsize=(25, 10))\n",
    "    librosa.display.specshow(log_mel_spectrogram, \n",
    "                             x_axis=\"time\",\n",
    "                             y_axis=\"mel\", \n",
    "                             sr=sr)\n",
    "    plt.colorbar(format=\"%+2.f\")\n",
    "    plt.savefig(output_path)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting MFCC for Classic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "# Set up parameters for MFCC extraction\n",
    "n_fft = 2048\n",
    "hop_length = 512\n",
    "n_mels = 128\n",
    "n_mfcc = 20\n",
    "\n",
    "# Set up folder paths\n",
    "input_folder = \"D:\\Education\\Semester 6\\CSE 321 Project Based Learning on CSE\\Classification_Classic-Modern\\Classic\\Segmented\"\n",
    "output_folder = \"D:\\Education\\Semester 6\\CSE 321 Project Based Learning on CSE\\Classification_Classic-Modern\\Classic\\MFCC\"\n",
    "\n",
    "# Loop over files in input folder\n",
    "for file_name in os.listdir(input_folder):\n",
    "    # Check if file is a WAV file\n",
    "    if not file_name.endswith('.wav'):\n",
    "        continue\n",
    "\n",
    "    # Load audio file using librosa\n",
    "    file_path = os.path.join(input_folder, file_name)\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "\n",
    "    # Compute MFCCs\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels, n_mfcc=n_mfcc)\n",
    "\n",
    "    # Save MFCCs to file\n",
    "    output_path = os.path.join(output_folder, file_name.replace('.wav', '_mfcc.npy'))\n",
    "    np.save(output_path, mfcc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting MFCC for Modern Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "# Set up parameters for MFCC extraction\n",
    "n_fft = 2048\n",
    "hop_length = 512\n",
    "n_mels = 128\n",
    "n_mfcc = 20\n",
    "\n",
    "# Set up folder paths\n",
    "input_folder = \"D:\\Education\\Semester 6\\CSE 321 Project Based Learning on CSE\\Classification_Classic-Modern\\Modern\\Segmented\"\n",
    "output_folder = \"D:\\Education\\Semester 6\\CSE 321 Project Based Learning on CSE\\Classification_Classic-Modern\\Modern\\MFCC\"\n",
    "\n",
    "# Loop over files in input folder\n",
    "for file_name in os.listdir(input_folder):\n",
    "    # Check if file is a WAV file\n",
    "    if not file_name.endswith('.wav'):\n",
    "        continue\n",
    "\n",
    "    # Load audio file using librosa\n",
    "    file_path = os.path.join(input_folder, file_name)\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "\n",
    "    # Compute MFCCs\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels, n_mfcc=n_mfcc)\n",
    "\n",
    "    # Save MFCCs to file\n",
    "    output_path = os.path.join(output_folder, file_name.replace('.wav', '_mfcc.npy'))\n",
    "    np.save(output_path, mfcc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "path = r\"D:\\Education\\Semester 6\\CSE 321 Project Based Learning on CSE\\Classification_Classic-Modern\\Modern\\MFCC_np\\335- تعليم عزف اغنية انا في الغرام - شيرين_segment1_mfcc.npy\"\n",
    "\n",
    "file = np.load(path)\n",
    "print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing X_train and Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define the paths to the two folders\n",
    "Classic = \"D:\\Education\\Semester 6\\CSE 321 Project Based Learning on CSE\\Classification_Classic-Modern\\Classic\\MFCC_np\"\n",
    "Modern = \"D:\\Education\\Semester 6\\CSE 321 Project Based Learning on CSE\\Classification_Classic-Modern\\Modern\\MFCC_np\"\n",
    "\n",
    "# Define the maximum number of columns\n",
    "max_columns = 469\n",
    "\n",
    "# Initialize X and y lists\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# Load data from folder1\n",
    "for file_name in os.listdir(Classic):\n",
    "    if file_name.endswith('.npy'):\n",
    "        # Load the Numpy array\n",
    "        data = np.load(os.path.join(Classic, file_name))\n",
    "        \n",
    "        # Pad the array with zeros to have the same number of columns\n",
    "        data_padded = np.pad(data, ((0, 0), (0, max_columns - data.shape[1])), mode='constant')\n",
    "        \n",
    "        # Append the padded array and label to X and y lists\n",
    "        X.append(data_padded)\n",
    "        y.append(0)\n",
    "\n",
    "# Load data from folder2\n",
    "for file_name in os.listdir(Modern):\n",
    "    if file_name.endswith('.npy'):\n",
    "        # Load the Numpy array\n",
    "        data = np.load(os.path.join(Modern, file_name))\n",
    "        \n",
    "        # Pad the array with zeros to have the same number of columns\n",
    "        data_padded = np.pad(data, ((0, 0), (0, max_columns - data.shape[1])), mode='constant')\n",
    "        \n",
    "        # Append the padded array and label to X and y lists\n",
    "        X.append(data_padded)\n",
    "        y.append(1)\n",
    "\n",
    "# Convert X and y lists to NumPy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Print the shapes of X and y\n",
    "print('X shape:', X.shape)\n",
    "print('y shape:', y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_train.shape[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Add a 2D convolutional layer with 32 filters, a 3x3 kernel size, and ReLU activation\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=X_train.shape[1:]))\n",
    "\n",
    "# Add a max pooling layer with a pool size of 2x2\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Add a second 2D convolutional layer with 64 filters, a 3x3 kernel size, and ReLU activation\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# Add a second max pooling layer with a pool size of 2x2\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the output of the convolutional layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add a dense layer with 128 units and ReLU activation\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "# Add a dropout layer with a rate of 0.5\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Add the output layer with 1 unit and a sigmoid activation for binary classification\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model with binary cross-entropy loss and Adam optimizer\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model.save(\"D:\\Education\\Semester 6\\CSE 321 Project Based Learning on CSE\\Classification_Classic-Modern\\model_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_acc = model.evaluate(X_train, y_train, verbose=2)\n",
    "print('Train accuracy:', train_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "plt.plot(fpr, tpr, label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='lower right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_pred)\n",
    "average_precision = average_precision_score(y_test, y_pred)\n",
    "plt.plot(recall, precision, label='Precision-Recall curve (AP = %0.2f)' % average_precision)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(loc='lower right')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MP3TOWAV(mp3_file):\n",
    "    if mp3_file.endswith(\".mp3\"):\n",
    "        # Load MP3 file using pydub\n",
    "        audio = AudioSegment.from_file(mp3_file)\n",
    "        \n",
    "        # Export the audio file to a WAV file in memory\n",
    "        wav_file = io.BytesIO()\n",
    "        audio.export(wav_file, format=\"wav\")\n",
    "        wav_file.seek(0)\n",
    "\n",
    "        # Load the WAV file into memory using librosa.load()\n",
    "        y, sr = librosa.load(wav_file, sr=None)\n",
    "        return y, sr\n",
    "\n",
    "def Norm(audio):\n",
    "    return librosa.util.normalize(audio)\n",
    "\n",
    "def Segment(audio, sr):\n",
    "    segment_length = 5\n",
    "    hop_length = 2\n",
    "    Segmented = []\n",
    "    \n",
    "    # Calculate segment frame and sample lengths\n",
    "    segment_frames = int(segment_length * sr)\n",
    "    hop_frames = int(hop_length * sr)\n",
    "    total_frames = len(audio)\n",
    "    total_segments = int((total_frames - segment_frames) / hop_frames) + 1\n",
    "\n",
    "    # Segment audio using a sliding window\n",
    "    for i in range(total_segments):\n",
    "        # Calculate start and end frame indices for current segment\n",
    "        start_frame = i * hop_frames\n",
    "        end_frame = start_frame + segment_frames\n",
    "\n",
    "        # Extract audio segment\n",
    "        y_segment = audio[start_frame:end_frame]\n",
    "        Segmented.append(y_segment)\n",
    "    return Segmented\n",
    "    \n",
    "def MFCC(audio, sr):\n",
    "    # Extracting MFCC\n",
    "    # Set up parameters for MFCC extraction\n",
    "    n_fft = 2048\n",
    "    hop_length = 512\n",
    "    n_mels = 128\n",
    "    n_mfcc = 20\n",
    "\n",
    "    # Compute MFCCs\n",
    "    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels, n_mfcc=n_mfcc)\n",
    "    \n",
    "    num_frames = 469\n",
    "    frame_length = 20\n",
    "    n_frames = mfcc.shape[1]\n",
    "    n_features = mfcc.shape[0]\n",
    "    \n",
    "    # If the number of frames is less than num_frames, pad with zeros\n",
    "    if n_frames < num_frames:\n",
    "        mfcc_padded = np.zeros((n_features, num_frames))\n",
    "        mfcc_padded[:, :n_frames] = mfcc\n",
    "        return mfcc_padded\n",
    "    \n",
    "    # If the number of frames is greater than num_frames, trim to num_frames\n",
    "    elif n_frames > num_frames:\n",
    "        return mfcc[:, :num_frames]\n",
    "    \n",
    "    # If the number of frames is already num_frames, return the original MFCC array\n",
    "    else:\n",
    "        return mfcc\n",
    "\n",
    "def predict(model_path, file_path):\n",
    "    audio, sr = MP3TOWAV(file_path)\n",
    "    norm_audio = Norm(audio)\n",
    "    segmented_audio = Segment(norm_audio, sr)\n",
    "    mfcc_audio = []\n",
    "    for audio_index in segmented_audio:\n",
    "        audio_mfcc = MFCC(audio_index, sr)\n",
    "        mfcc_audio.append(audio_mfcc)\n",
    "    \n",
    "    arr = np.array(mfcc_audio)\n",
    "    model = load_model(model_path)\n",
    "    y = model.predict(arr)\n",
    "    output = (sum(y)/len(y))\n",
    "    if (output < 0.5):\n",
    "        return \"Classic\"\n",
    "    else:\n",
    "        return \"Modern\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"D:\\Education\\Semester 6\\CSE 321 Project Based Learning on CSE\\Classification_Classic-Modern\\test.mp3\"\n",
    "model_path = \"D:\\Education\\Semester 6\\CSE 321 Project Based Learning on CSE\\Classification_Classic-Modern\\model_1\"\n",
    "\n",
    "x = predict(model_path, file_path)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP/kfIam9E2Bpjex6qNFsMD",
   "mount_file_id": "1QtTZZGSPa9odsdYOSDiieHebx9K70h_7",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
